{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.4.0-cp38-cp38-manylinux2010_x86_64.whl (394.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 394.8 MB 13 kB/s s eta 0:00:01  |▊                               | 8.4 MB 6.8 MB/s eta 0:00:58     |▉                               | 10.6 MB 6.8 MB/s eta 0:00:57     |█                               | 13.7 MB 7.9 MB/s eta 0:00:49     |██▏                             | 26.1 MB 6.6 MB/s eta 0:00:56     |███▍                            | 41.6 MB 7.0 MB/s eta 0:00:51     |████▍                           | 54.7 MB 393 kB/s eta 0:14:25     |████▌                           | 56.0 MB 8.4 MB/s eta 0:00:41     |████▋                           | 56.4 MB 8.4 MB/s eta 0:00:41     |█████▏                          | 63.6 MB 7.5 MB/s eta 0:00:45     |███████                         | 85.4 MB 7.3 MB/s eta 0:00:43     |████████                        | 97.3 MB 6.9 MB/s eta 0:00:44     |████████▋                       | 106.8 MB 8.3 MB/s eta 0:00:35     |██████████▎                     | 126.4 MB 6.3 MB/s eta 0:00:43     |███████████▉                    | 146.2 MB 8.5 MB/s eta 0:00:30     |████████████                    | 148.3 MB 8.5 MB/s eta 0:00:30     |████████████▉                   | 158.2 MB 6.7 MB/s eta 0:00:36     |██████████████▏                 | 175.0 MB 5.7 MB/s eta 0:00:39     |██████████████▋                 | 180.3 MB 5.7 MB/s eta 0:00:38     |████████████████                | 198.6 MB 5.1 MB/s eta 0:00:39     |█████████████████               | 210.6 MB 12.1 MB/s eta 0:00:16     |█████████████████▉              | 220.1 MB 6.8 MB/s eta 0:00:26     |██████████████████▏             | 224.3 MB 6.8 MB/s eta 0:00:25     |███████████████████▏            | 235.8 MB 9.5 MB/s eta 0:00:17     |████████████████████            | 245.8 MB 9.1 MB/s eta 0:00:17     |████████████████████▋           | 253.6 MB 7.7 MB/s eta 0:00:19     |█████████████████████           | 257.7 MB 9.9 MB/s eta 0:00:14     |█████████████████████▎          | 262.7 MB 10.2 MB/s eta 0:00:13     |█████████████████████▍          | 263.8 MB 10.2 MB/s eta 0:00:13     |█████████████████████▊          | 268.1 MB 10.2 MB/s eta 0:00:13     |█████████████████████▉          | 269.0 MB 4.6 MB/s eta 0:00:28     |██████████████████████▌         | 277.6 MB 12.9 MB/s eta 0:00:10     |███████████████████████         | 284.1 MB 9.1 MB/s eta 0:00:13     |███████████████████████▎        | 286.6 MB 9.1 MB/s eta 0:00:12     |███████████████████████▋        | 290.7 MB 9.1 MB/s eta 0:00:12     |███████████████████████▉        | 294.2 MB 15.7 MB/s eta 0:00:07     |████████████████████████▏       | 297.5 MB 15.7 MB/s eta 0:00:07     |████████████████████████▋       | 303.0 MB 9.0 MB/s eta 0:00:11     |████████████████████████▉       | 305.9 MB 5.5 MB/s eta 0:00:17     |██████████████████████████      | 320.8 MB 5.0 MB/s eta 0:00:15     |███████████████████████████     | 331.8 MB 10.5 MB/s eta 0:00:06     |███████████████████████████     | 332.7 MB 10.5 MB/s eta 0:00:06     |████████████████████████████▎   | 349.2 MB 6.6 MB/s eta 0:00:07     |████████████████████████████▉   | 355.2 MB 5.4 MB/s eta 0:00:08     |████████████████████████████▉   | 356.0 MB 9.6 MB/s eta 0:00:05     |█████████████████████████████▏  | 360.0 MB 9.6 MB/s eta 0:00:04     |█████████████████████████████▎  | 360.8 MB 9.6 MB/s eta 0:00:04     |██████████████████████████████▎ | 373.9 MB 6.4 MB/s eta 0:00:04\n",
      "\u001b[?25hCollecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/kapoorlab/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting wheel~=0.35\n",
      "  Downloading wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp38-cp38-manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py~=2.10.0 in /home/kapoorlab/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 502 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy~=1.19.2\n",
      "  Using cached numpy-1.19.4-cp38-cp38-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 7.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/kapoorlab/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.2)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 7.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 815 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 5.6 MB/s eta 0:00:01    |███████████▉                    | 3.9 MB 6.7 MB/s eta 0:00:02     |███████████████████████         | 7.6 MB 5.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.14.0-cp38-cp38-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "\u001b[K     |████████████████████████████████| 779 kB 6.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /home/kapoorlab/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/kapoorlab/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/kapoorlab/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (49.2.0.post20200714)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 783 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.0-py3-none-any.whl (12 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 8.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.6-py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 689 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/kapoorlab/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kapoorlab/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/kapoorlab/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/kapoorlab/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 850 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 8.0 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: wrapt, termcolor\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-linux_x86_64.whl size=77135 sha256=7d2e6bd95b29011e2bb7b93cdf6dc7c6a236bed6a190e4d158edf2999e822ec7\n",
      "  Stored in directory: /home/kapoorlab/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=bbff4ed4afcd837d505d76563781201ed71a5a27cd5b24807a55247cd0e0ae16\n",
      "  Stored in directory: /home/kapoorlab/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built wrapt termcolor\n",
      "Installing collected packages: wrapt, wheel, termcolor, grpcio, numpy, opt-einsum, absl-py, gast, flatbuffers, astunparse, keras-preprocessing, tensorflow-estimator, google-pasta, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, tensorboard-plugin-wit, protobuf, oauthlib, requests-oauthlib, google-auth-oauthlib, markdown, tensorboard, tensorflow\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.34.2\n",
      "    Uninstalling wheel-0.34.2:\n",
      "      Successfully uninstalled wheel-0.34.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n",
      "Successfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.2.0 flatbuffers-1.12 gast-0.3.3 google-auth-1.24.0 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.32.0 keras-preprocessing-1.1.2 markdown-3.3.3 numpy-1.19.4 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.14.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.6 tensorboard-2.4.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0 termcolor-1.1.0 wheel-0.36.2 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from glob import glob\n",
    "!pip install tensorflow\n",
    "sys.path.append(\"../\")\n",
    "from NEATModels import NEATDetection, nets\n",
    "from NEATModels.config import NeatConfig\n",
    "from NEATUtils import helpers\n",
    "\n",
    "from NEATUtils.helpers import save_json\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataDir = '/data/u934/service_imagerie/v_kapoor/CSVforNeat/YolONEAT/CenterTrainData/'\n",
    "Model_dir = '/data/u934/service_imagerie/CurieTrainingDatasets/YolONEAT/CurieDeepLearningModels/YolONEAT/'\n",
    "Model_Name = 'ORYolo.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network parameters\n",
    "#For ORNET use residual = True and for OSNET use residual = False\n",
    "residual = True\n",
    "#NUmber of starting convolutional filters, is doubled down with increasing depth\n",
    "startfilter = 48\n",
    "#CNN network start layer, mid layers and lstm layer kernel size\n",
    "start_kernel = 3\n",
    "lstm_kernel = 3\n",
    "mid_kernel = 3\n",
    "#Network depth has to be 9n + 2, n= 3 or 4 is optimal for Notum dataset\n",
    "depth = 29\n",
    "#Training epochs, longer the better zith proper chosen leqrning rate\n",
    "epochs = 150\n",
    "#Size of the gradient descent length vector, start small and use callbacs to get smaller when reaching the minima\n",
    "learning_rate = 1.0E-4\n",
    "#For stochastic gradient decent, the batch size used for computing the gradients\n",
    "batch_size = 10\n",
    "#Number of LSTM hidden layers > time sequence used for training\n",
    "lstm = 16\n",
    "# use softmax for single event per box, sigmoid for multi event per box\n",
    "multievent = False\n",
    "#X Y T H W Confidence Angle makes up the box vector\n",
    "categories = 6\n",
    "box_vector = 7\n",
    "# Grid and anchor boxes for yolo\n",
    "gridX = 1\n",
    "gridY = 1\n",
    "nboxes = 5\n",
    "#Weightage to co-ordinate loss term\n",
    "lambdacord = 5\n",
    "#X Y T- T+\n",
    "crop_size = [256,256,4,5]\n",
    "sizeX = crop_size[0]\n",
    "sizeY = crops_size[1]\n",
    "sizeTminus = crop_size[2]\n",
    "sizeTplus = crop_size[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = NeatConfig(residual = residual, startfilter = startfilter, start_kernel = start_kernel, \n",
    "                    mid_kernel = mid_kernel,lstm_kernel = lstm_kernel, categories = categories,\n",
    "                    box_vector = box_vector,\n",
    "                    depth = depth, lstm = lstm, learning_rate = learning_rate, batch_size = batch_size,\n",
    "                    epochs = epochs, ModelName = Model_Name, sizeX = sizeX, sizeY = sizeY,\n",
    "                    sizeTminus = sizeTminus, sizeTplus = sizeTplus,\n",
    "                    gridX = gridX, gridY = gridY, nboxes = nboxes, lambdacord = lambdacord, multievent = multievent)\n",
    "\n",
    "config_json = config.to_json()\n",
    "show = True\n",
    "\n",
    "model_weights = Model_dir + Model_Name\n",
    "\n",
    "if os.path.exists(model_weights):\n",
    "\n",
    "    model_weights = model_weights\n",
    "    print('loading weights')\n",
    "else:\n",
    "   \n",
    "    model_weights = None\n",
    "\n",
    "Categories_Name = []\n",
    "Categories_Name.append(['Normal', 0])\n",
    "Categories_Name.append(['Apoptosis', 1])\n",
    "Categories_Name.append(['Divisions', 2])\n",
    "Categories_Name.append(['MacroKitty', 3])\n",
    "Categories_Name.append(['NonMatureP1', 4])\n",
    "Categories_Name.append(['MatureP1', 5])\n",
    "print(config)\n",
    "save_json(config_json, Model_dir + Model_Name + 'Param.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = NEATDetection(config, TrainDataDir, Categories_Name, box_vector, Model_dir, Model_Name, model_weights = model_weights, show = show)\n",
    "\n",
    "Train.loadData()\n",
    "\n",
    "Train.TrainModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
