{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unlimited-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "sys.path.append(\"../\")\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from NEATUtils import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interim-artwork",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of  images:\t 1689\n",
      "image size:\t\t (1689, 128, 128, 1)\n",
      "Labels:\t\t\t\t (1689, 1, 1, 9)\n"
     ]
    }
   ],
   "source": [
    "ImageLabelDir = '/home/sancere/Kepler/FinalONEATTraining/StaticCenterTrainData/'\n",
    "categories = 4\n",
    "anchors = [0.11,0.11, 0.17,0.19, 0.26,0.29, 0.37,0.37, 0.62,0.55]\n",
    "nbxes = len(anchors)//2\n",
    "(X,Y), (X_val,Y_val) = helpers.load_full_training_data(ImageLabelDir, categories, nboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nervous-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestAnchorBoxFinder(object):\n",
    "    def __init__(self, ANCHORS):\n",
    "        '''\n",
    "        ANCHORS: a np.array of even number length e.g.\n",
    "        \n",
    "        _ANCHORS = [4,2, ##  width=4, height=2,  flat large anchor box\n",
    "                    2,4, ##  width=2, height=4,  tall large anchor box\n",
    "                    1,1] ##  width=1, height=1,  small anchor box\n",
    "        '''\n",
    "        self.anchors = [BoundBox(0, 0, ANCHORS[2*i], ANCHORS[2*i+1]) \n",
    "                        for i in range(int(len(ANCHORS)//2))]\n",
    "        \n",
    "    def _interval_overlap(self,interval_a, interval_b):\n",
    "        x1, x2 = interval_a\n",
    "        x3, x4 = interval_b\n",
    "        if x3 < x1:\n",
    "            if x4 < x1:\n",
    "                return 0\n",
    "            else:\n",
    "                return min(x2,x4) - x1\n",
    "        else:\n",
    "            if x2 < x3:\n",
    "                 return 0\n",
    "            else:\n",
    "                return min(x2,x4) - x3  \n",
    "\n",
    "    def bbox_iou(self,box1, box2):\n",
    "        intersect_w = self._interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "        intersect_h = self._interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])  \n",
    "\n",
    "        intersect = intersect_w * intersect_h\n",
    "\n",
    "        w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "        w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "\n",
    "        union = w1*h1 + w2*h2 - intersect\n",
    "\n",
    "        return float(intersect) / union\n",
    "    \n",
    "    def find(self,center_w, center_h):\n",
    "        # find the anchor that best predicts this box\n",
    "        best_anchor = -1\n",
    "        max_iou     = -1\n",
    "        # each Anchor box is specialized to have a certain shape.\n",
    "        # e.g., flat large rectangle, or small square\n",
    "        shifted_box = BoundBox(0, 0,center_w, center_h)\n",
    "        ##  For given object, find the best anchor box!\n",
    "        for i in range(len(self.anchors)): ## run through each anchor box\n",
    "            anchor = self.anchors[i]\n",
    "            iou    = self.bbox_iou(shifted_box, anchor)\n",
    "            if max_iou < iou:\n",
    "                best_anchor = i\n",
    "                max_iou     = iou\n",
    "        return(best_anchor,max_iou)    \n",
    "    \n",
    "    \n",
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, confidence=None,classes=None):\n",
    "        self.xmin, self.ymin = xmin, ymin\n",
    "        self.xmax, self.ymax = xmax, ymax\n",
    "        ## the code below are used during inference\n",
    "        # probability\n",
    "        self.confidence      = confidence\n",
    "        # class probaiblities [c1, c2, .. cNclass]\n",
    "        self.set_class(classes)\n",
    "        \n",
    "    def set_class(self,classes):\n",
    "        self.classes = classes\n",
    "        self.label   = np.argmax(self.classes) \n",
    "        \n",
    "    def get_label(self):  \n",
    "        return(self.label)\n",
    "    \n",
    "    def get_score(self):\n",
    "        return(self.classes[self.label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "resistant-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "class ImageReader(object):\n",
    "    def __init__(self,IMAGE_H,IMAGE_W, norm=None):\n",
    "        '''\n",
    "        IMAGE_H : the height of the rescaled image, e.g., 416\n",
    "        IMAGE_W : the width of the rescaled image, e.g., 416\n",
    "        '''\n",
    "        self.IMAGE_H = IMAGE_H\n",
    "        self.IMAGE_W = IMAGE_W\n",
    "        self.norm    = norm\n",
    "        \n",
    "    def encode_core(self,image, reorder_rgb=True):     \n",
    "        # resize the image to standard size\n",
    "        image = cv2.resize(image, (self.IMAGE_H, self.IMAGE_W))\n",
    "        if reorder_rgb:\n",
    "            image = image[:,:,::-1]\n",
    "        if self.norm is not None:\n",
    "            image = self.norm(image)\n",
    "        return(image)\n",
    "    \n",
    "    def fit(self,train_instance):\n",
    "    \n",
    "        if not isinstance(train_instance,dict):\n",
    "            train_instance = {'filename':train_instance}\n",
    "                \n",
    "        image_name = train_instance['filename']\n",
    "        image = cv2.imread(image_name)\n",
    "        h, w, c = image.shape\n",
    "        if image is None: print('Cannot find ', image_name)\n",
    "      \n",
    "        image = self.encode_core(image, reorder_rgb=True)\n",
    "            \n",
    "        if \"object\" in train_instance.keys():\n",
    "            \n",
    "            all_objs = copy.deepcopy(train_instance['object'])     \n",
    "\n",
    "            # fix object's position and size\n",
    "            for obj in all_objs:\n",
    "                for attr in ['xmin', 'xmax']:\n",
    "                    obj[attr] = int(obj[attr] * float(self.IMAGE_W) / w)\n",
    "                    obj[attr] = max(min(obj[attr], self.IMAGE_W), 0)\n",
    "\n",
    "                for attr in ['ymin', 'ymax']:\n",
    "                    obj[attr] = int(obj[attr] * float(self.IMAGE_H) / h)\n",
    "                    obj[attr] = max(min(obj[attr], self.IMAGE_H), 0)\n",
    "        else:\n",
    "            return image\n",
    "        return image, all_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-advice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "oriental-hammer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import Sequence\n",
    "\n",
    "class SimpleBatchGenerator(Sequence):\n",
    "    def __init__(self, images, config, norm=None, shuffle=True):\n",
    "        \n",
    "        self.config = config\n",
    "        self.config[\"BOX\"] = int(len(self.config['ANCHORS'])/2)\n",
    "        self.config[\"CLASS\"] = len(self.config['LABELS'])\n",
    "        self.images = images\n",
    "        self.bestAnchorBoxFinder = BestAnchorBoxFinder(config['ANCHORS'])\n",
    "        self.imageReader = ImageReader(config['IMAGE_H'],config['IMAGE_W'],norm=norm)\n",
    "        self.shuffle = shuffle\n",
    "        if self.shuffle: \n",
    "            np.random.shuffle(self.images)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(float(len(self.images))/self.config['BATCH_SIZE']))  \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        == input == \n",
    "        \n",
    "        idx : non-negative integer value e.g., 0\n",
    "        \n",
    "        == output ==\n",
    "        \n",
    "        x_batch: The numpy array of shape  (BATCH_SIZE, IMAGE_H, IMAGE_W, N channels).\n",
    "            \n",
    "            x_batch[iframe,:,:,:] contains a iframeth frame of size  (IMAGE_H,IMAGE_W).\n",
    "            \n",
    "        y_batch:\n",
    "\n",
    "            The numpy array of shape  (BATCH_SIZE, GRID_H, GRID_W, BOX, 4 + 1 + N classes). \n",
    "            BOX = The number of anchor boxes.\n",
    "\n",
    "            y_batch[iframe,igrid_h,igrid_w,ianchor,:4] contains (center_x,center_y,center_w,center_h) \n",
    "            of ianchorth anchor at  grid cell=(igrid_h,igrid_w) if the object exists in \n",
    "            this (grid cell, anchor) pair, else they simply contain 0.\n",
    "\n",
    "            y_batch[iframe,igrid_h,igrid_w,ianchor,4] contains 1 if the object exists in this \n",
    "            (grid cell, anchor) pair, else it contains 0.\n",
    "\n",
    "            y_batch[iframe,igrid_h,igrid_w,ianchor,5 + iclass] contains 1 if the iclass^th \n",
    "            class object exists in this (grid cell, anchor) pair, else it contains 0.\n",
    "\n",
    "\n",
    "        b_batch:\n",
    "\n",
    "            The numpy array of shape (BATCH_SIZE, 1, 1, 1, TRUE_BOX_BUFFER, 4).\n",
    "\n",
    "            b_batch[iframe,1,1,1,ibuffer,ianchor,:] contains ibufferth object's \n",
    "            (center_x,center_y,center_w,center_h) in iframeth frame.\n",
    "\n",
    "            If ibuffer > N objects in iframeth frame, then the values are simply 0.\n",
    "\n",
    "            TRUE_BOX_BUFFER has to be some large number, so that the frame with the \n",
    "            biggest number of objects can also record all objects.\n",
    "\n",
    "            The order of the objects do not matter.\n",
    "\n",
    "            This is just a hack to easily calculate loss. \n",
    "        \n",
    "        '''\n",
    "        l_bound = idx*self.config['BATCH_SIZE']\n",
    "        r_bound = (idx+1)*self.config['BATCH_SIZE']\n",
    "\n",
    "        if r_bound > len(self.images):\n",
    "            r_bound = len(self.images)\n",
    "            l_bound = r_bound - self.config['BATCH_SIZE']\n",
    "\n",
    "        instance_count = 0\n",
    "        \n",
    "        ## prepare empty storage space: this will be output\n",
    "        x_batch = np.zeros((r_bound - l_bound, self.config['IMAGE_H'], self.config['IMAGE_W'], 3))                         # input images\n",
    "        b_batch = np.zeros((r_bound - l_bound, 1     , 1     , 1    ,  self.config['TRUE_BOX_BUFFER'], 4))   # list of self.config['TRUE_self.config['BOX']_BUFFER'] GT boxes\n",
    "        y_batch = np.zeros((r_bound - l_bound, self.config['GRID_H'],  self.config['GRID_W'], self.config['BOX'], 4+1+len(self.config['LABELS'])))                # desired network output\n",
    "\n",
    "        for train_instance in self.images[l_bound:r_bound]:\n",
    "            # augment input image and fix object's position and size\n",
    "            img, all_objs = self.imageReader.fit(train_instance)\n",
    "            \n",
    "            # construct output from object's x, y, w, h\n",
    "            true_box_index = 0\n",
    "            \n",
    "            for obj in all_objs:\n",
    "                if obj['xmax'] > obj['xmin'] and obj['ymax'] > obj['ymin'] and obj['name'] in self.config['LABELS']:\n",
    "                    center_x, center_y = rescale_centerxy(obj,self.config)\n",
    "                    \n",
    "                    grid_x = int(np.floor(center_x))\n",
    "                    grid_y = int(np.floor(center_y))\n",
    "\n",
    "                    if grid_x < self.config['GRID_W'] and grid_y < self.config['GRID_H']:\n",
    "                        obj_indx  = self.config['LABELS'].index(obj['name'])\n",
    "                        center_w, center_h = rescale_cebterwh(obj,self.config)\n",
    "                        box = [center_x, center_y, center_w, center_h]\n",
    "                        best_anchor,max_iou = self.bestAnchorBoxFinder.find(center_w, center_h)\n",
    "                                \n",
    "                        # assign ground truth x, y, w, h, confidence and class probs to y_batch\n",
    "                        # it could happen that the same grid cell contain 2 similar shape objects\n",
    "                        # as a result the same anchor box is selected as the best anchor box by the multiple objects\n",
    "                        # in such ase, the object is over written\n",
    "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 0:4] = box # center_x, center_y, w, h\n",
    "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 4  ] = 1. # ground truth confidence is 1\n",
    "                        y_batch[instance_count, grid_y, grid_x, best_anchor, 5+obj_indx] = 1 # class probability of the object\n",
    "                        \n",
    "                        # assign the true box to b_batch\n",
    "                        b_batch[instance_count, 0, 0, 0, true_box_index] = box\n",
    "                        \n",
    "                        true_box_index += 1\n",
    "                        true_box_index = true_box_index % self.config['TRUE_BOX_BUFFER']\n",
    "                            \n",
    "            x_batch[instance_count] = img\n",
    "            # increase instance counter in current batch\n",
    "            instance_count += 1  \n",
    "        return [x_batch, b_batch], y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle: \n",
    "            np.random.shuffle(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ruled-circus",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5d709e566d52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m train_batch_generator = SimpleBatchGenerator(train_image, generator_config,\n\u001b[0m\u001b[1;32m     20\u001b[0m                                              norm=normalize, shuffle=True)\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_image' is not defined"
     ]
    }
   ],
   "source": [
    "IMAGE_H, IMAGE_W = 128, 128\n",
    "BATCH_SIZE       = 16\n",
    "TRUE_BOX_BUFFER  = 50\n",
    "GRID_H = 1\n",
    "GRID_W = 1\n",
    "StaticLabel = [0, 1, 2, 3]\n",
    "generator_config = {\n",
    "    'IMAGE_H'         : IMAGE_H, \n",
    "    'IMAGE_W'         : IMAGE_W,\n",
    "    'GRID_H'          : GRID_H,  \n",
    "    'GRID_W'          : GRID_W,\n",
    "    'LABELS'          : StaticLabel,\n",
    "    'ANCHORS'         : anchors,\n",
    "    'BATCH_SIZE'      : BATCH_SIZE,\n",
    "    'TRUE_BOX_BUFFER' : TRUE_BOX_BUFFER,\n",
    "}\n",
    "\n",
    "\n",
    "train_batch_generator = SimpleBatchGenerator(X, generator_config,\n",
    "                                             norm=normalize, shuffle=True)\n",
    "\n",
    "[x_batch,b_batch],y_batch = train_batch_generator.__getitem__(idx=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_batch: (BATCH_SIZE, IMAGE_H, IMAGE_W, N channels)           = {}\".format(x_batch.shape))\n",
    "print(\"y_batch: (BATCH_SIZE, GRID_H, GRID_W, BOX, 4 + 1 + N classes) = {}\".format(y_batch.shape))\n",
    "print(\"b_batch: (BATCH_SIZE, 1, 1, 1, TRUE_BOX_BUFFER, 4)            = {}\".format(b_batch.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
