{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Star Dist and Smart ONEAT \n",
    "In this notebook we combine Star Dist and ONEAT to predict events.\n",
    "\n",
    "1) To use this notebook you need to provide the directory where images are written live\n",
    "\n",
    "2) The CSV file with events will be written in Results folder inside that folder\n",
    "\n",
    "\n",
    "Other attributes to be specified are mentioned below, you have to fill those fields before running the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import sys\n",
    "sys.path.append(\"../NEAT\")\n",
    "from tifffile import imread, imwrite\n",
    "from NEATUtils.MultiModelPrediction import SmartPredONEAT, ConvertModel\n",
    "from NEATUtils.helpers import MarkerToCSV\n",
    "from keras.models import load_model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from NEATModels import mid_yolo_loss,simple_yolo_loss, Concat\n",
    "try:\n",
    "    from pathlib import Path\n",
    "    Path().expanduser()\n",
    "except (ImportError,AttributeError):\n",
    "    from pathlib2 import Path\n",
    "try:\n",
    "    import tempfile\n",
    "    tempfile.TemporaryDirectory\n",
    "except (ImportError,AttributeError):\n",
    "    from backports import tempfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction specific Attributes\n",
    "\n",
    "1) In the cell below specify the directory of the NEAT trained models\n",
    "\n",
    "2) The directory where files are written\n",
    "\n",
    "3) Since Neat was trained on a 55 by 55 pixel images that means about 7 or 8 cells should come inside this view, which is true for binning 2 movies but if you are using binning 1 and the program takes care of other things but needs to know if the movie is binning 1 or 2\n",
    "\n",
    "4) Number of GPU's, if you have more than one GPU we can split the job of finding the markers and running ONEAT on them\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/usr_app/VarunAnaconda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/usr_app/VarunAnaconda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/usr_app/VarunAnaconda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/usr_app/VarunAnaconda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/usr_app/VarunAnaconda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/usr_app/VarunAnaconda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/usr_app/VarunAnaconda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/usr_app/VarunAnaconda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/usr_app/VarunAnaconda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/usr_app/VarunAnaconda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/usr_app/VarunAnaconda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/usr_app/VarunAnaconda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/usr_app/VarunAnaconda/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/usr_app/VarunAnaconda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/usr_app/VarunAnaconda/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /data/usr_app/VarunAnaconda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/usr_app/VarunAnaconda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ModelDirectory = '/data/u934/service_imagerie/v_kapoor/CurieDeepLearningModels/O-NEATweights/'\n",
    "MovieDir =  '/data/u934/service_imagerie/v_kapoor/ONEAT_fly_test/'\n",
    "ResultsDirectory = '/data/u934/service_imagerie/v_kapoor/ONEAT_fly_test/Results/'\n",
    "\n",
    "#Center ONEAT\n",
    "CenterONEATA = 'FourFrameCenterPredORNETd29K3'\n",
    "CenterONEATB = 'FourFrameCenterPredOSNETd29K3'\n",
    "\n",
    "ConfigFileA = ModelDirectory + ONEATA + '.json'\n",
    "ConfigFileB = ModelDirectory + ONEATB + '.json'\n",
    "\n",
    "#Type of model decides the loss function used\n",
    "multievent = False\n",
    "\n",
    "Path(ResultsDirectory).mkdir(exist_ok = True)\n",
    "DownsampleFactor = 2\n",
    "n_tiles = 4\n",
    "TimeFrames = 4\n",
    "categories = 6\n",
    "TrainshapeX = 54\n",
    "TrainshapeY = 54\n",
    "sizeTminus = 3\n",
    "cutoff = 1.0 - 1.0E-8\n",
    "\n",
    "ConvertModel(ModelDirectory, CenterONEATA)\n",
    "ConvertModel(ModelDirectory, CenterONEATB)\n",
    "\n",
    "if classicNEAT:\n",
    "\n",
    " NEATA =  load_model( ModelDirectory + CenterONEATA + '.h5',  custom_objects={'loss':mid_yolo_loss(categories), 'Concat':Concat})\n",
    " NEATB =  load_model( ModelDirectory + CenterONEATB + '.h5',  custom_objects={'loss':mid_yolo_loss(categories), 'Concat':Concat})\n",
    "\n",
    "\n",
    "if centerNEAT:\n",
    "\n",
    " NEATA =  load_model( ModelDirectory + CenterONEATA + '.h5',  custom_objects={'loss':cat_simple_yolo_loss(categories), 'Concat':Concat})\n",
    " NEATB =   load_model( ModelDirectory + CenterONEATB + '.h5',  custom_objects={'loss':cat_simple_yolo_loss(categories), 'Concat':Concat})\n",
    "\n",
    "if simplecenterNEAT:\n",
    " NEATA =  load_model( ModelDirectory + CenterONEATA + '.h5',  custom_objects={'loss':simple_yolo_loss(categories), 'Concat':Concat})\n",
    " NEATB =  load_model( ModelDirectory + CenterONEATB + '.h5',  custom_objects={'loss':simple_yolo_loss(categories), 'Concat':Concat})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded, now listening to events\n",
      "Starting Movie Number 0\n",
      "Ending Movie Number 4\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPages: invalid page offset 2097160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPages: invalid page offset 2097160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPages: invalid page offset 2097160\n",
      "100%|██████████| 4/4 [00:00<00:00, 573.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "Predicting on Movies: ['main_acq__w1CSU-QUAD-488_s1_t1', 'main_acq__w1CSU-QUAD-488_s1_t2', 'main_acq__w1CSU-QUAD-488_s1_t3', 'main_acq__w1CSU-QUAD-488_s1_t4']\n",
      "(4, 1024, 1024)\n",
      "Resizing the image\n",
      "Predicting via center ONEAT\n",
      "Models loaded, now listening to events\n",
      "Starting Movie Number 1\n",
      "Ending Movie Number 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPages: invalid page offset 2097160\n",
      "100%|██████████| 4/4 [00:00<00:00, 1189.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "Predicting on Movies: ['main_acq__w1CSU-QUAD-488_s1_t2', 'main_acq__w1CSU-QUAD-488_s1_t3', 'main_acq__w1CSU-QUAD-488_s1_t4', 'main_acq__w1CSU-QUAD-488_s1_t5']\n",
      "(4, 1024, 1024)\n",
      "Resizing the image\n",
      "Predicting via center ONEAT\n",
      "Models loaded, now listening to events\n",
      "Starting Movie Number 2\n",
      "Ending Movie Number 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPages: invalid page offset 2097160\n",
      "100%|██████████| 4/4 [00:00<00:00, 1270.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "Predicting on Movies: ['main_acq__w1CSU-QUAD-488_s1_t3', 'main_acq__w1CSU-QUAD-488_s1_t4', 'main_acq__w1CSU-QUAD-488_s1_t5', 'main_acq__w1CSU-QUAD-488_s1_t6']\n",
      "(4, 1024, 1024)\n",
      "Resizing the image\n",
      "Predicting via center ONEAT\n",
      "Models loaded, now listening to events\n",
      "Starting Movie Number 3\n",
      "Ending Movie Number 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPages: invalid page offset 2097160\n",
      "100%|██████████| 4/4 [00:00<00:00, 1026.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n",
      "Predicting on Movies: ['main_acq__w1CSU-QUAD-488_s1_t4', 'main_acq__w1CSU-QUAD-488_s1_t5', 'main_acq__w1CSU-QUAD-488_s1_t6', 'main_acq__w1CSU-QUAD-488_s1_t7']\n",
      "(4, 1024, 1024)\n",
      "Resizing the image\n",
      "Predicting via center ONEAT\n",
      "Models loaded, now listening to events\n",
      "Starting Movie Number 4\n",
      "Ending Movie Number 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPages: invalid page offset 2097160\n",
      "100%|██████████| 4/4 [00:00<00:00, 952.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n",
      "Predicting on Movies: ['main_acq__w1CSU-QUAD-488_s1_t5', 'main_acq__w1CSU-QUAD-488_s1_t6', 'main_acq__w1CSU-QUAD-488_s1_t7', 'main_acq__w1CSU-QUAD-488_s1_t8']\n",
      "(4, 1024, 1024)\n",
      "Resizing the image\n",
      "Predicting via center ONEAT\n",
      "Models loaded, now listening to events\n",
      "Starting Movie Number 5\n",
      "Ending Movie Number 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "SmartPredONEAT(MovieDir, ResultsDirectory, NEATA, NEATB,  DownsampleFactor,[], [], 0,  classicNEAT = classicNEAT, \n",
    "                   TimeFrames = TimeFrames, Mode = 'Prediction',categories = categories, TrainshapeX = TrainshapeX, TrainshapeY = TrainshapeY, cut = cutoff, sizeTminus = sizeTminus, n_tiles = n_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
